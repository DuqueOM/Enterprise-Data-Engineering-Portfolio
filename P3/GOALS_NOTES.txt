This file lists concrete steps to achieve the requested goals for P3.

Scope: P3 is the API/model service with monitoring and deployment.

1) README TL;DR
- Already present; add brief 'curl /version' [P4] (done in README).

2) Publish dataset / model to HF
- Dataset handled by P2/P4; P3 can push model artifacts if trained here.
- If adding LoRA smoke: run train_lora.py with small steps; push to HF via huggingface_hub.

3) Eval script (F1/EM + latency)
- Retrieval eval implemented in P4/scripts/eval.py. P3 focuses on latency/metrics via Prometheus.

4) LEGAL.md
- Use central LEGAL.md at repo root; P3 references it for API usage terms.

5) CI smoke .github/workflows/ci_smoke.yml
- You can add a CI to run pytest on tests/ and a smoke uvicorn boot. Not strictly required now.

6) DVC pipeline
- Not applicable (service). Lives in P4.

7) k6 stress tests + canary
- Run against P3 API; store scripts under k6/ in repo root or in P3/k6. Add promote_canary.sh and rollback if your cluster is live.

8) W&B runs & artifacts
- For training flows, publish W&B runs with screenshots in README.

9) Colab notebook
- Provide quickstart to hit API endpoints from Colab.
