# ğŸ¢ PYME QA Dataset - DataOps & CI/CD Pipeline

[![DataOps Pipeline](https://github.com/yourusername/p2-dataset-dataops/actions/workflows/dataops.yml/badge.svg)](https://github.com/yourusername/p2-dataset-dataops/actions/workflows/dataops.yml)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **ImplementaciÃ³n profesional de DataOps + CI/CD para datasets**  
> Un sistema automatizado para recopilar, validar, versionar y desplegar datos de QA para trÃ¡mites administrativos de PYMEs.

## ğŸ¯ Â¿QuÃ© es este proyecto?

Este proyecto implementa una soluciÃ³n completa de **DataOps** que trata los datos como un producto. En lugar de manejar archivos Excel desorganizados, creamos un pipeline automatizado que:

âœ… **Ahorra tiempo y costos** - Evita errores manuales en los datos  
âœ… **Mejora la calidad** - ValidaciÃ³n automÃ¡tica y mÃ©tricas de calidad  
âœ… **Facilita colaboraciÃ³n** - Equipos pueden trabajar con datos confiables  
âœ… **Control de versiones** - Siempre sabes quÃ© versiÃ³n de los datos se usÃ³  
âœ… **Escalable** - Se puede replicar en otros proyectos sin empezar de cero  

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚â”€â”€â”€â–¶â”‚   Ingestion      â”‚â”€â”€â”€â–¶â”‚   Validation    â”‚
â”‚   (Websites)    â”‚    â”‚   (Scripts)      â”‚    â”‚   (Schema/QA)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Annotation    â”‚â—€â”€â”€â”€â”‚   Processing     â”‚â—€â”€â”€â”€â”‚   Quality       â”‚
â”‚   (Label Studio)â”‚    â”‚   (Cleaning)     â”‚    â”‚   Analysis      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Deployment    â”‚â—€â”€â”€â”€â”‚   Model Train    â”‚â—€â”€â”€â”€â”‚   Versioning    â”‚
â”‚   (Production)  â”‚    â”‚   (Baseline)     â”‚    â”‚   (DVC/Git)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estructura del Proyecto

```
P2/
â”œâ”€â”€ .github/workflows/          # CI/CD pipelines
â”‚   â””â”€â”€ dataops.yml            # GitHub Actions workflow
â”œâ”€â”€ data/                       # Datos (versionados con DVC)
â”‚   â”œâ”€â”€ raw/                   # Datos originales (no en Git)
â”‚   â”œâ”€â”€ processed/             # Datos procesados
â”‚   â””â”€â”€ annotation/            # Datos para anotaciÃ³n
â”œâ”€â”€ scripts/                    # Scripts del pipeline
â”‚   â”œâ”€â”€ ingest.py              # RecolecciÃ³n de datos
â”‚   â”œâ”€â”€ clean.py               # Limpieza de datos
â”‚   â”œâ”€â”€ validate_schema.py     # ValidaciÃ³n de esquema
â”‚   â”œâ”€â”€ data_quality.py        # AnÃ¡lisis de calidad
â”‚   â”œâ”€â”€ train_baseline.py      # Modelo baseline
â”‚   â””â”€â”€ annotate.py            # PreparaciÃ³n para anotaciÃ³n
â”œâ”€â”€ notebooks/                  # AnÃ¡lisis exploratorio
â”‚   â””â”€â”€ EDA.ipynb              # Jupyter notebook para EDA
â”œâ”€â”€ tests/                      # Tests automatizados
â”‚   â””â”€â”€ test_schema.py         # Tests de validaciÃ³n
â”œâ”€â”€ models/                     # Modelos entrenados
â”œâ”€â”€ reports/                    # Reportes de calidad
â”œâ”€â”€ metrics/                    # MÃ©tricas del pipeline
â”œâ”€â”€ dvc.yaml                   # DefiniciÃ³n del pipeline DVC
â”œâ”€â”€ requirements.txt           # Dependencias Python
â””â”€â”€ README.md                  # Este archivo
```

## ğŸš€ GuÃ­a de Inicio RÃ¡pido

### Prerrequisitos

- Python 3.9 o superior
- Git
- Opcional: Docker (para Label Studio)
- Opcional: Cuenta en GitHub/GitLab (para CI/CD)

### Paso 1: Clonar y Configurar Entorno

```bash
# Clonar el repositorio
git clone <URL-DEL-REPOSITORIO>
cd P2

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate     # Windows

# Instalar dependencias
pip install --upgrade pip
pip install -r requirements.txt
```

### Paso 2: Configurar DVC (Data Version Control)

```bash
# Inicializar DVC
dvc init

# Configurar remote storage (opcional)
# Ejemplo con Google Drive:
dvc remote add -d myremote gdrive://<ID-CARPETA>
# O con S3:
dvc remote add -d myremote s3://bucket-name/path

# Push datos existentes (si hay)
dvc push
```

### Paso 3: Ejecutar el Pipeline Localmente

```bash
# 1. Recolectar datos (con flags opcionales)
python scripts/ingest.py \
  --output data/processed/faqs.jsonl \
  --region "Antioquia" \
  --chunk-size 1500

# 2. Limpiar datos
python scripts/clean.py

# 3. Validar esquema y calidad
python scripts/validate_schema.py

# 4. AnÃ¡lisis de calidad
python scripts/data_quality.py

# 5. Entrenar modelo baseline
python scripts/train_baseline.py

# O ejecutar todo con DVC
dvc repro
```

### Paso 4: Configurar AnotaciÃ³n (Opcional)

```bash
# Iniciar Label Studio con Docker
docker run -it -p 8080:8080 -v $(pwd)/data:/label-studio/data heartexlabs/label-studio:latest

# Configurar variables de entorno
export LABEL_STUDIO_URL="http://localhost:8080"
export LABEL_STUDIO_API_KEY="TU-API-KEY"
export LABEL_STUDIO_PROJECT_ID="1"

# Importar tareas para anotaciÃ³n
python scripts/annotate.py
```

### Paso 5: Analizar Resultados

```bash
# Abrir Jupyter para anÃ¡lisis exploratorio
jupyter notebook notebooks/EDA.ipynb

# Ver reporte de calidad
open reports/quality_report.html
```

## ğŸ”§ ConfiguraciÃ³n del Pipeline

### Personalizar Fuentes de Datos

Edita `scripts/ingest.py` para agregar tus propias URLs:

```python
urls = [
    ("https://sitio-gubernamental-1.gov/faq", "Antioquia"),
    ("https://sitio-gubernamental-2.gov/faq", "Valle del Cauca"),
    # Agrega mÃ¡s URLs aquÃ­
]
```

### Configurar Validaciones

Modifica `scripts/validate_schema.py` para ajustar reglas de validaciÃ³n:

```python
SCHEMA = {
    "required": ["id", "source_url", "text", "date_fetched"],
    "properties": {
        "text": {"minLength": 50},  # MÃ­nimo 50 caracteres
        # ... mÃ¡s reglas
    }
}
```

### Personalizar MÃ©tricas de Calidad

Edita `scripts/data_quality.py` para agregar mÃ©tricas personalizadas:

```python
def custom_quality_checks(df):
    # Agrega tus propias validaciones
    pass
```

## ğŸ”„ CI/CD Pipeline

El pipeline automatizado se ejecuta automÃ¡ticamente cuando:

- **Push a main/develop**: Ejecuta validaciÃ³n, tests y entrenamiento
- **Pull Request**: Ejecuta tests de calidad
- **Manual**: Puede dispararse manualmente desde GitHub

### Stages del Pipeline

1. **Data Validation**: Valida esquema y calidad de datos
2. **Data Tests**: Ejecuta tests automatizados
3. **Security Scan**: Escanea vulnerabilidades
4. **Model Monitoring**: Verifica performance del modelo
5. **Deploy**: Despliega a staging/producciÃ³n

### Configurar Secrets en GitHub

Ve a `Settings > Secrets and variables > Actions` y configura:

- `DVC_REMOTE_URL`: URL del storage remoto
- `SLACK_WEBHOOK_URL`: Para notificaciones (opcional)

## ğŸ“Š MÃ©tricas y Monitoreo

### MÃ©tricas AutomÃ¡ticas

El pipeline genera automÃ¡ticamente:

- **Completitud**: Porcentaje de datos no nulos
- **Unicidad**: DetecciÃ³n de duplicados
- **Consistencia**: ValidaciÃ³n de formatos
- **Calidad de texto**: Longitud, caracteres especiales
- **Performance del modelo**: Accuracy, features importantes

### Reportes

- **HTML Report**: `reports/quality_report.html`
- **JSON Metrics**: `metrics/quality.json`
- **Model Metrics**: `models/metrics.json`

## ğŸ› Troubleshooting

### Problemas Comunes

**Error: "File not found" en validaciÃ³n**
```bash
# AsegÃºrate de haber ejecutado los pasos anteriores
python scripts/ingest.py
python scripts/clean.py
```

**Error: DVC remote no configurado**
```bash
# Configura un remote o usa local storage
dvc remote add -d local /tmp/dvc-storage
```

**Error: Dependencias faltantes**
```bash
# Reinstala todas las dependencias
pip install -r requirements.txt --force-reinstall
```

### Logs y Debugging

```bash
# Ver logs detallados
export PYTHONPATH=$(pwd)
python -v scripts/validate_schema.py

# Ver estado del pipeline DVC
dvc status
dvc dag
```

## ğŸš€ Despliegue a ProducciÃ³n

### OpciÃ³n 1: GitHub Actions (AutomÃ¡tico)

El pipeline se despliega automÃ¡ticamente al hacer push a `main`.

### OpciÃ³n 2: Manual

```bash
# 1. Versionar datos
dvc add data/processed/faqs_clean.jsonl
dvc push

# 2. Crear tag de versiÃ³n
git tag dataset-v1.0.0
git push origin dataset-v1.0.0

# 3. Desplegar a producciÃ³n
# (agrega comandos especÃ­ficos de tu infraestructura)
```

### IntegraciÃ³n con Hugging Face

```python
from datasets import Dataset
import json

# Cargar datos
with open('data/processed/faqs_clean.jsonl', 'r') as f:
    data = [json.loads(line) for line in f]

# Crear dataset
dataset = Dataset.from_list(data)

# Subir a Hugging Face
dataset.push_to_hub("tu-username/pyme-qa-dataset")
```

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
pytest tests/ -v

# Ejecutar tests con coverage
pytest tests/ --cov=scripts --cov-report=html

# Ejecutar tests especÃ­ficos
pytest tests/test_schema.py -v
```

## ğŸ“ˆ Escalando el Proyecto

### Para Datasets MÃ¡s Grandes

1. **Procesamiento Paralelo**:
```python
from multiprocessing import Pool
with Pool(processes=4) as pool:
    results = pool.map(process_url, urls)
```

2. **Cloud Storage**:
```bash
# Configurar S3
dvc remote add -d s3 s3://bucket-name
dvc push
```

3. **Distributed Computing**:
Considera usar Dask o Spark para datasets muy grandes.

### Para MÃºltiples Fuentes

```python
# Agregar soporte para APIs, bases de datos, etc.
def fetch_from_api(endpoint):
    # LÃ³gica para API
    pass

def fetch_from_database(query):
    # LÃ³gica para base de datos
    pass
```

## ğŸ¤ ContribuciÃ³n

1. Fork el repositorio
2. Crear rama de feature: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -am 'Agregar nueva funcionalidad'`
4. Push a la rama: `git push origin feature/nueva-funcionalidad`
5. Abrir Pull Request

## ğŸ“„ Licencia

MIT License - ver archivo [LICENSE](LICENSE) para detalles.

## ğŸ™ Agradecimientos

- [DVC](https://dvc.org/) - Para versionado de datos
- [Label Studio](https://labelstud.io/) - Para anotaciÃ³n de datos
- [Pandera](https://pandera.readthedocs.io/) - Para validaciÃ³n de datos
- [Scikit-learn](https://scikit-learn.org/) - Para modelos baseline

## ğŸ“ Soporte

- ğŸ“§ Email: [tu-email@ejemplo.com]
- ğŸ’¬ Slack: [canal-de-soporte]
- ğŸ“– Docs: [enlace-a-documentaciÃ³n]
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/p2-dataset-dataops/issues)

---

**ğŸ‰ Â¡Listo! Ahora tienes un pipeline de DataOps profesional automatizado.**

Para empezar, simplemente ejecuta:
```bash
git clone <URL>
cd P2
pip install -r requirements.txt
python scripts/ingest.py
```

Y sigue los pasos descritos en esta guÃ­a.


---

## IntegraciÃ³n opcional con P4 [P4]

Para emitir los datos directamente al formato/ubicaciÃ³n esperada por P4, usa:

```bash
python scripts/ingest.py \
  --output ../P4/data/raw/faqs_p2_compatible.jsonl \
  --region "BogotÃ¡" \
  --chunk-size 1500  # [P4]
```

Notas:
- El flag `--output` es opcional y no cambia el comportamiento por defecto.  # [P4]
- El formato generado es compatible con P2 y P4 (JSONL con campos id, source_url, region, text, date_fetched).  # [P4]
- Esto no afecta la ejecuciÃ³n independiente del proyecto P2.  # [P4]

